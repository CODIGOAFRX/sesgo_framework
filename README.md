GSMFair â€“ Mini-framework local para mitigar sesgo en clasificaciÃ³n (CV screening)

GSMFair es una librerÃ­a ligera y local (sin nube) para posprocesar las predicciones de un clasificador y reducir la disparidad entre grupos (p. ej., gÃ©nero) en FPR (false positive rate) y FNR (false negative rate).
EstÃ¡ pensada para demos y auditorÃ­a offline: no reentrena tu modelo; ajusta las salidas finales para equilibrar errores entre grupos y generar informes reproducibles.

âœ¨ CaracterÃ­sticas

Dos estrategias de mitigaciÃ³n:

EqualizeFprFnr â†’ ajusta umbrales por grupo cuando existen scores/probabilidades.

equalize_rates_from_binary â†’ reduce gaps sÃ³lo con predicciÃ³n binaria (sin scores) â€œflippingâ€ un mÃ­nimo de FP/FN por grupo hasta acercarlos al mejor grupo.

IntegraciÃ³n plug-and-play con archivos existentes en reports/ (predicciones_thr.csv).

Informes listos para memoria/TFM: reports/metrics_genero.txt y CSV con predicciones mitigadas.

Funciona 100% en local (Windows/VS Code probado).

ğŸ“¦ InstalaciÃ³n

Requisitos: Python 3.9+ (recomendado virtualenv).

# Clona tu repo (o copia la carpeta)
# Crea y activa entorno (Windows PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1

# Instala dependencias y el paquete en modo editable
pip install -U pip
pip install -r requirements.txt   # si existe
pip install -e .


El paquete se instala como gsmfair desde src/.

ğŸ“ Estructura (mÃ­nima)
gms-cv/
â”œâ”€ data/                         # (opcional) datasets originales
â”œâ”€ models/                       # (opcional) modelos .joblib/.pkl
â”œâ”€ reports/
â”‚  â””â”€ predicciones_thr.csv       # ENTRADA: gÃ©nero, label, preseleccionado (+ opcional score)
â”œâ”€ src/
â”‚  â”œâ”€ gsmfair/
â”‚  â”‚  â””â”€ mitigation/
â”‚  â”‚     â”œâ”€ postprocessing.py    # EqualizeFprFnr + equalize_rates_from_binary
â”‚  â”‚     â””â”€ __init__.py
â”‚  â””â”€ metrics_genero.py          # Script de auditorÃ­a+mitigaciÃ³n
â””â”€ pyproject.toml


reports/predicciones_thr.csv debe contener como mÃ­nimo:

genero (H/M o 0/1), label (0/1), preseleccionado (0/1).

(Opcional) una columna de score: score, prob, prob_pos, y_score, etc.

ğŸš€ Uso rÃ¡pido

AsegÃºrate de tener reports/predicciones_thr.csv.

Ejecuta:

python src/metrics_genero.py


Revisa los resultados:

reports/metrics_genero.txt â†’ Baseline vs Fair, por grupo y global.

reports/predicciones_thr_fair.csv â†’ aÃ±ade preseleccionado_fair con la salida mitigada.

Objetivo de demo: mostrar que FPR gap y FNR gap (diferencias entre H y M) disminuyen tras la mitigaciÃ³n.

ğŸ”§ CÃ³mo funciona
A) Si tu CSV trae scores/probabilidades

Se usa EqualizeFprFnr:

from gsmfair.mitigation import EqualizeFprFnr
pp = EqualizeFprFnr(alpha=0.5, grid_size=401, clip=(0.01, 0.99))
pp.fit(y_true_val=y_true, y_scores_val=y_scores, s_val=s, ref_threshold=0.5)
y_pred_fair = pp.predict(y_scores=y_scores, s=s)


alpha: 1.0 prioriza FPR, 0.0 prioriza FNR, 0.5 equilibra.

grid_size: resoluciÃ³n para buscar el umbral por grupo (â†‘ = mÃ¡s fino).

B) Si tu CSV no trae scores (solo 0/1)

Se usa equalize_rates_from_binary:

from gsmfair.mitigation import equalize_rates_from_binary
y_pred_fair, info = equalize_rates_from_binary(
    y_true=y_true, y_pred=y_pred_base, s=s, alpha=0.5, seed=7
)


QuÃ© hace: reduce FPR en el grupo con exceso de FP (cambiando algunos FP â†’ 0) y reduce FNR en el grupo con exceso de FN (cambiando algunos FN â†’ 1), hasta acercarlos al mejor grupo.

Ventaja: no necesita probabilidades; vÃ¡lido para auditorÃ­a offline.

âš™ï¸ ParÃ¡metros recomendados

ALPHA en metrics_genero.py:

0.3 â†’ prioriza bajar FNR gap (recuperar positivos).

0.8 â†’ prioriza bajar FPR gap (evitar falsos positivos).

0.5 â†’ equilibrio (valor por defecto).

GRID=401 (aumenta a 801 si usas EqualizeFprFnr y quieres mÃ¡s precisiÃ³n).

TREF=0.5 umbral global de referencia (para el mÃ©todo de umbral por grupo).

ğŸ“Š MÃ©tricas clave en el informe

TP: verdaderos positivos; FP: falsos positivos; TN, FN.

Precision = TP / (TP+FP)

Recall (TPR) = TP / (TP+FN)

FPR = FP / (FP+TN)

FNR = FN / (FN+TP)

Gaps: |FPR_H âˆ’ FPR_M| y |FNR_H âˆ’ FNR_M| (objetivo: bajar).

âœ… Ejemplo real (tus resultados)

Tras aplicar equalize_rates_from_binary sobre tus predicciones:

FPR gap: 0.1609 â†’ 0.0804 (âˆ’50%)

FNR gap: 0.1435 â†’ 0.0717 (âˆ’50%)

Globalmente, bajan FP y FN, suben precision, F1 y accuracy.

Se imprime ademÃ¡s un resumen de â€œflipsâ€ por grupo, p. ej.:
{'0': {'flip_FP_to_0': 1829, 'flip_FN_to_1': 0}, '1': {'flip_FP_to_0': 0, 'flip_FN_to_1': 127}}

ğŸ§ª Reproducibilidad y buenas prÃ¡cticas

Usa la misma semilla (seed) para obtener resultados idÃ©nticos.

Versiona los informes metrics_genero.txt y los CSV con sufijos de fecha.

Para informes acadÃ©micos, guarda tambiÃ©n el diff Baseline â†’ Fair.

ğŸ› ï¸ SoluciÃ³n de problemas

â€œNo encuentra columnasâ€: asegÃºrate de que predicciones_thr.csv tenga genero, label, preseleccionado.
Si tus nombres son distintos, renÃ³mbralos o adapta el parser.

â€œTengo scores pero no cambia nadaâ€: revisa que la columna de score sea continua y estÃ© bien mapeada a la clase positiva (p. ej., prob_pos).

â€œQuiero reducir aÃºn mÃ¡s FNR/FPR gapâ€: sube/baja ALPHA y, si usas EqualizeFprFnr, aumenta GRID.

ğŸ¤ Contribuir

Issues y PRs bienvenidos.

Estilo: PEP8, mensajes de commit descriptivos, tests mÃ­nimos si tocas mitigaciÃ³n.
